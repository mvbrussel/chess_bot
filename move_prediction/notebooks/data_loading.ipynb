{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating and reviewing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import gym\n",
    "import gym_chess\n",
    "import chess\n",
    "from gym_chess.alphazero import BoardEncoding\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import shutil\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing created local modules\n",
    "cwd = os.getcwd()\n",
    "parent_directory = os.path.abspath(os.path.join(cwd, \"..\", \"..\"))\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "from utils.move_encoding import encode_move, decode_move\n",
    "from utils.board_encoding import encode_board, fen_to_board\n",
    "from utils.find_move import find_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading settings\n",
    "\n",
    "The dataset used is an obtained from [Lichess](https://database.lichess.org/), with +1M chess games and ~37M chess moves. The database is not included in the repository given size limitation. The features in the database are: \n",
    "\n",
    "- id: the unique move ID\n",
    "- FEN (Forsyth-Edwards Notation): a standard notation for describing a particular board position of a chess game using a single line of text\n",
    "- eval: the evaluation score of the move\n",
    "\n",
    "Part of the database is used, to limit the running time and GPU usage. This is determined below, by setting:\n",
    "\n",
    "- n_observations: the total number of observations (chess moves) to include\n",
    "- step_size: the steps in which the data is processed, used to keep the reduce the working memory needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to be set\n",
    "n_observations = 10000000\n",
    "step_size = 10000\n",
    "folder_name = \"10M\"\n",
    "\n",
    "# Creating the directories\n",
    "folder_path = f\"../../data/cleaned_data/{folder_name}\"\n",
    "\n",
    "\"\"\" Only exectute the below if the folder should be removed and re-created if it already exists \"\"\"\n",
    "# if os.path.exists(folder_path):\n",
    "#     shutil.rmtree(folder_path)\n",
    "\n",
    "os.makedirs(folder_path)\n",
    "output_files = []\n",
    "\n",
    "# Connecting to the database\n",
    "database = sqlite3.connect(\"../../data/lichess_game_data.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the data\n",
    "\n",
    "A step-wise processing of the data is executed below. In each loop, a part of the database is processed and a .pkl of the cleaned dataframe is created in the folder identified above.\n",
    "\n",
    "Steps in the data processing are:\n",
    "1. **An encoded board position is obtained from the FEN.** Following the approach in the AlphaZero paper, a board position is encoded into an (8,8,119) shaped array. \n",
    "2. **The move made for a given board position is obtained.** This is done using the current and next board FEN\n",
    "3. **The move is encoded.** Following the approach in the AlphaZero paper, a move is encoded into an (4672,) shaped array\n",
    "\n",
    "\n",
    "Details on the encoding can be found in the [AlphaZero paper](https://arxiv.org/abs/1712.01815) and in the board_encoding & move_encoding utility files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(database, start_index, step_size, output_file):\n",
    "    \"\"\"\n",
    "    Processes data from a database, encodes board states and moves, and saves the processed data to a file.\n",
    "\n",
    "    Args:\n",
    "        database (str or sqlite3.Connection): The database connection, containing the lichess data\n",
    "        start_index (int): The starting index from which to fetch data.\n",
    "        step_size (int): The number of records to fetch from the database.\n",
    "        output_file (str): The path to the output file where the processed data will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the data from the database\n",
    "    query = f\"SELECT * FROM evaluations LIMIT {step_size} OFFSET {start_index}\"\n",
    "    df = pd.read_sql_query(query, database)\n",
    "\n",
    "    # Obtain the encoded board for each observation\n",
    "    df[\"board\"] = df[\"fen\"].apply(fen_to_board)\n",
    "    df[\"encoded_board\"] = df[\"board\"].apply(encode_board)\n",
    "\n",
    "    # Obtain the move that was made for each observation, given the current and next board position\n",
    "    df[\"next_fen\"] = df[\"fen\"].shift(-1)\n",
    "    df = df.dropna(subset=[\"next_fen\"]).reset_index(drop=True)\n",
    "    df[\"move\"] = df.apply(lambda row: find_move(row[\"fen\"], row[\"next_fen\"]), axis=1)\n",
    "    df = df.dropna(subset=[\"move\"]).reset_index(drop=True)\n",
    "\n",
    "    # Encode the move\n",
    "    df[\"encoded_move\"] = df.apply(\n",
    "        lambda row: encode_move(row[\"move\"], row[\"board\"]), axis=1\n",
    "    )\n",
    "    df.dropna(subset=[\"encoded_move\"], inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Save the relevant dataframe\n",
    "    df = df[[\"encoded_board\", \"encoded_move\"]]\n",
    "    df.to_pickle(output_file)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement loop for step-wise data processing\n",
    "for start_index in range(0, n_observations, step_size):\n",
    "    output_file = f\"{folder_path}/processed_step_{start_index}.pkl\"\n",
    "    process_data(database, start_index, step_size, output_file)\n",
    "    output_files.append(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Lists all files in the specified folder, including their full paths.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder whose files are to be listed.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of full paths to the files in the specified folder.\n",
    "    \"\"\"\n",
    "\n",
    "    files = os.listdir(folder_path)\n",
    "    files_with_path = [os.path.join(folder_path, file) for file in files]\n",
    "\n",
    "    return files_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the combined dataframe\n",
    "output_files = list_files_in_folder(folder_path)\n",
    "final_df = pd.concat([pd.read_pickle(file) for file in output_files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_board</th>\n",
       "      <th>encoded_move</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...</td>\n",
       "      <td>1905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       encoded_board  encoded_move\n",
       "0  [[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...           877\n",
       "1  [[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...           731\n",
       "2  [[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...           803\n",
       "3  [[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...          1905\n",
       "4  [[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...          1394\n",
       "5  [[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...           129\n",
       "6  [[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...           129\n",
       "7  [[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...           876\n",
       "8  [[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...           154\n",
       "9  [[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...           415"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of moves is: 9479998\n",
      "The total number of unique moves is: 1846\n",
      "The total number of missing observations is: 0\n"
     ]
    }
   ],
   "source": [
    "# Print summary information of the dataset\n",
    "n_moves = len(final_df)\n",
    "n_unique_moves = len(final_df[\"encoded_move\"].unique())\n",
    "n_missing_obs = len(final_df[final_df.isna().any(axis=\"columns\")])\n",
    "\n",
    "display(final_df.head(10))\n",
    "print(f\"The total number of moves is: {n_moves}\")\n",
    "print(f\"The total number of unique moves is: {n_unique_moves}\")\n",
    "print(f\"The total number of missing observations is: {n_missing_obs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess_bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
